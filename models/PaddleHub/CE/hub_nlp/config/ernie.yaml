MODEL: "ernie" # 模型名称
PRIORITY: P0
GIT:
  addr: $REPO_PaddleHub
  path: $ROOT_PATH/PaddleHub
  branch: $NLP_BRANCH

ENV:
  PADDLE_ON_MODEL_CE: $PADDLE_ON_MODEL_CE

VARIABLES:
  model_scripts_path: scripts/nlp1/ #脚本的路径
  model_log_path: log/ernie

EXEC:
  exec_cases: [INSTALL, FINETUNE, PREDICT, UNINSTALL]
  exec_priority: [p0, p1]
  exec_tag: $EXEC_TAG

#测试套
INSTALL:
  -
    priority: p0
    tag: install_module
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: bash nlp_install.sh ernie
    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_install.log

FINETUNE:
  -
    priority: p0
    tag: linux_mini-finetune_mini-epoch_gpu1
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, train_data, use_gpu, batch_size, num_epoch, dataset,
    # optimizer, learning_rate, max_seq_len, save_interval, checkpoint_dir
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: bash nlp_finetune.sh ernie text-matching dev True 16 1 LCQMC Adam 1e-5 128 1 save

    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_finetune_text-matching_dev_True_16_1_LCQMC_Adam_1e-5_128_1_save.log

  -
    priority: p0
    tag: win_mini-finetune_mini-epoch_gpu1
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, train_data, use_gpu, batch_size, num_epoch, dataset, optimizer, save_interval
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: nlp_finetune.bat ernie text-matching dev True 8 1 LCQMC Adam 1

    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_finetune_text-matching_dev_True_8_1_LCQMC_Adam_1.log

  -
    priority: p1
    tag: linux_finetune_mini-epoch_gpu1
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, train_data, use_gpu, batch_size, num_epoch, dataset,
    # optimizer, learning_rate, max_seq_len, save_interval, checkpoint_dir
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: bash nlp_finetune.sh ernie text-matching train True 16 4 LCQMC Adam 1e-5 128 2 save

    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_finetune_text-matching_train_True_16_4_LCQMC_Adam_1e-5_128_2_save.log

PREDICT:
  -
    priority: p0
    tag: linux_predict_without_model_gpu1
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, use_finetune_model, use_gpu, max_seq_len, batch_size
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: bash nlp_predict.sh ernie text-matching False True 128 1
    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_predict_text-matching_False_True_128_1.log

  -
    priority: p0
    tag: win_predict_without_model_gpu1
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, use_finetune_model, use_gpu, max_seq_len, batch_size
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: nlp_predict.bat ernie text-matching False True 128 1
    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_predict_text-matching_False_True_128_1.log

  -
    priority: p0
    tag: win_predict_without_model_cpu
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, use_finetune_model, use_gpu, max_seq_len, batch_size
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: nlp_predict.bat ernie text-matching False False 128 1
    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_predict_text-matching_False_False_128_1.log

  -
    priority: p0
    tag: mac_predict_without_model_cpu
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, use_finetune_model, use_gpu, max_seq_len, batch_size
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: bash nlp_predict.sh ernie text-matching False False 128 1
    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_predict_text-matching_False_False_128_1.log

  -
    priority: p1
    tag: linux_predict_with_model_gpu1
    env: #去掉，自动调度
      CUDA_VISIBLE_DEVICES: $SET_CUDA  #取值为None，则不设置

    # task, use_finetune_model, use_gpu, max_seq_len, batch_size
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: bash nlp_predict.sh ernie text-matching True True 128 1
    kpis:
      exit_code:
        latest: True
        kpi_base: 0
        threshold: 0
        actived: True
        evaluation: "-"
        unit_repr: None
    output: $ROOT_PATH/$model_log_path/EXIT_ernie_predict_text-matching_True_True_128_1.log

UNINSTALL:
  -
    priority: p0
    tag: uninstall_module
    run:
      -
        path: $ROOT_PATH/$model_scripts_path
        cmd: hub uninstall ernie
