


data_path:
    linux_data_path: /ssd2/ce_data/PaddleOCR/train_data
    windows_data_path: E:\ce_data\PaddleOCR\train_data
    mac_data_path: /Users/paddle/PaddleTest/ce_data/PaddleOCR/train_data 

cmd:
    det:
       train: 'cd PaddleOCR; export CUDA_VISIBLE_DEVICES=0; python -m paddle.distributed.launch  tools/train.py -c %s  -o Train.loader.batch_size_per_card=2 Global.use_gpu=%s Global.epoch_num=1 Global.save_epoch_step=1 Global.save_model_dir=output/%s'
       get_pretrained_model: 'cd PaddleOCR; wget %s; tar xf %s.tar; rm -rf *.tar; mv %s_train %s;'
       eval: 'cd PaddleOCR; python tools/eval.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy'
       infer: 'cd PaddleOCR; python tools/infer_det.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.infer_img="./doc/imgs_en/img_10.jpg" Global.test_batch_size_per_card=1'
       export_model: 'cd PaddleOCR; python tools/export_model.py -c %s -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.save_inference_dir=./models_inference/%s;'
       predict: 'cd PaddleOCR; python tools/infer/predict_det.py --image_dir="./doc/imgs_en/img_10.jpg" --det_model_dir="./models_inference/"%s --det_algorithm=%s --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s'
    rec:
       train: 'cd PaddleOCR; export CUDA_VISIBLE_DEVICES=0; sed -i s!data_lmdb_release/training!data_lmdb_release/validation!g %s; python -m paddle.distributed.launch tools/train.py -c %s -o Global.use_gpu=%s Global.epoch_num=1 Global.save_epoch_step=1 Global.eval_batch_step=200 Global.print_batch_step=10 Global.save_model_dir=output/%s Train.loader.batch_size_per_card=10 Global.print_batch_step=1;' 
       get_pretrained_model: 'cd PaddleOCR; wget %s; tar xf %s.tar; rm -rf *.tar; mv %s_train %s;' 
       eval: 'cd PaddleOCR; python tools/eval.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy'
       infer: 'cd PaddleOCR; python tools/infer_rec.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.infer_img="./doc/imgs_words/en/word_1.png";'
       export_model: 'cd PaddleOCR; python tools/export_model.py -c %s -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.save_inference_dir=./models_inference/%s;'
       predict: 'cd PaddleOCR; python tools/infer/predict_rec.py --image_dir="./doc/imgs_words_en/word_336.png" --rec_model_dir="./models_inference/"%s --rec_image_shape=%s --rec_algorithm=%s --rec_char_dict_path=%s --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s --use_space_char=False;'
    sr:
       train: 'cd PaddleOCR; export CUDA_VISIBLE_DEVICES=0; python -m paddle.distributed.launch tools/train.py -c %s -o Global.use_gpu=%s Global.epoch_num=1 Global.save_epoch_step=1 Global.eval_batch_step=200 Global.print_batch_step=10 Global.save_model_dir=output/%s Train.loader.batch_size_per_card=10 Global.print_batch_step=1;'
       get_pretrained_model: 'cd PaddleOCR; wget %s; tar xf %s.tar; rm -rf *.tar; mv %s_train %s;'
       eval: 'cd PaddleOCR; python tools/eval.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy'
       infer: 'cd PaddleOCR; python tools/infer_sr.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.infer_img="./doc/imgs_words_en/word_52.png";'
       export_model: 'cd PaddleOCR; python tools/export_model.py -c %s -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.save_inference_dir=./models_inference/%s;'
       predict: 'cd PaddleOCR; mkdir infer_result; python tools/infer/predict_sr.py --image_dir="./doc/imgs_words_en/word_52.png" --sr_model_dir="./models_inference/"%s --sr_image_shape=%s --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s --use_space_char=False;'
    kie/vi_layoutxlm:
       train: 'cd PaddleOCR; export CUDA_VISIBLE_DEVICES=0; python -m paddle.distributed.launch tools/train.py -c %s -o Global.use_gpu=%s Global.epoch_num=1 Global.save_epoch_step=1 Global.eval_batch_step=200 Global.print_batch_step=10 Global.save_model_dir=output/%s Train.loader.batch_size_per_card=10 Global.print_batch_step=1;'
       get_pretrained_model: 'cd PaddleOCR; wget %s; tar xf %s.tar; rm -rf *.tar; mv %s %s;'
       eval: 'cd PaddleOCR; python tools/eval.py -c %s  -o Global.use_gpu=%s Architecture.Backbone.checkpoints=./%s/best_accuracy'
       infer: 'cd PaddleOCR; python tools/infer_kie_token_ser.py -c %s -o Global.use_gpu=%s -o Architecture.Backbone.checkpoints=./%s/best_accuracy Global.infer_img=./train_data/XFUND/zh_val/val.json Global.infer_mode=False'
       export_model: 'cd PaddleOCR; python tools/export_model.py -c %s -o Global.use_gpu=%s Architecture.Backbone.checkpoints=./%s/best_accuracy Global.save_inference_dir=./models_inference/%s;'
       predict: 'cd PaddleOCR; python ppstructure/kie/predict_kie_token_ser.py --kie_algorithm=LayoutXLM --ser_model_dir=./models_inference/%s --image_dir=./ppstructure/docs/kie/input/zh_val_42.jpg --ser_dict_path=./train_data/XFUND/class_list_xfun.txt --vis_font_path=./doc/fonts/simfang.ttf --ocr_order_method="tb-yx" --shape_info_filename="shape.txt" --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s'

    table:
       train: 'cd PaddleOCR; export CUDA_VISIBLE_DEVICES=0; python -m paddle.distributed.launch tools/train.py -c %s -o Global.use_gpu=%s Global.epoch_num=1 Global.save_epoch_step=1 Global.eval_batch_step=500 Global.print_batch_step=1 Global.save_model_dir=output/%s Train.loader.batch_size_per_card=2 Global.print_batch_step=1 Train.dataset.data_dir=train_data/table/pubtabnet/val Train.dataset.label_file_list=[train_data/table/pubtabnet/val_500.jsonl] Eval.dataset.data_dir=train_data/table/pubtabnet/val Eval.loader.batch_size_per_card=10 Eval.dataset.label_file_list=[train_data/table/pubtabnet/val_500.jsonl]'
       get_pretrained_model: 'cd PaddleOCR; wget %s; tar xf %s.tar; rm -rf *.tar; mv %s %s;'
       eval: 'cd PaddleOCR; python tools/eval.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Eval.dataset.data_dir=train_data/table/pubtabnet/val Eval.loader.batch_size_per_card=10 Eval.dataset.label_file_list=[train_data/table/pubtabnet/val_500.jsonl]'
       infer: 'cd PaddleOCR; python tools/infer_table.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy -o  Global.infer_img=ppstructure/docs/table/table.jpg;'
       export_model: 'cd PaddleOCR; python tools/export_model.py -c %s -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.save_inference_dir=./models_inference/%s;'
       predict: 'cd PaddleOCR; python ppstructure/table/predict_structure.py --table_model_dir=./models_inference/%s --table_algorithm=TableMaster --table_char_dict_path=./ppocr/utils/dict/table_master_structure_dict.txt --table_max_len=480 --image_dir=ppstructure/docs/table/table.jpg --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s'
       predict_SLANet_ch: 'mkdir inference && cd inference;wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_slim_infer.tar && tar xf ch_PP-OCRv3_det_slim_infer.tar; wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_slim_infer.tar && tar xf ch_PP-OCRv3_rec_slim_infer.tar; wget https://paddleocr.bj.bcebos.com/ppstructure/models/slanet/ch_ppstructure_mobile_v2.0_SLANet_infer.tar && tar xf ch_ppstructure_mobile_v2.0_SLANet_infer.tar; cd ..; python ppstructure/table/predict_table.py --det_model_dir=inference/ch_PP-OCRv3_det_slim_infer --rec_model_dir=inference/ch_PP-OCRv3_rec_slim_infer --table_model_dir=inference/ch_ppstructure_mobile_v2.0_SLANet_infer --rec_char_dict_path=./ppocr/utils/ppocr_keys_v1.txt--table_char_dict_path=./ppocr/utils/dict/table_structure_dict_ch.txt --image_dir=ppstructure/docs/table/table.jpg --output=./output/table --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s'
       predict_SLANet: 'cd PaddleOCR; python ppstructure/table/predict_structure.py --image_dir=ppstructure/docs/table/table.jpg --table_model_dir=./models_inference/%s --table_char_dict_path=./ppocr/utils/dict/table_structure_dict.txt --table_max_len=488 --vis_font_path=./doc/fonts/simfang.ttf --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s'
    picodet/legacy_model/application/layout_analysis:
       train: 'cd PaddleDetection; python tools/train.py -c configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x1_0_layout.yml --eval -o epoch=1 use_gpu=%s'
       get_pretrained_model: 'cd PaddleDetection; mkdir pretrained_model; cd pretrained_model; wget https://paddleocr.bj.bcebos.com/ppstructure/models/layout/picodet_lcnet_x1_0_layout.pdparams; cd ..'
       eval: 'cd PaddleDetection; python tools/eval.py -c configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x1_0_layout.yml -o weights=pretrained_model/picodet_lcnet_x1_0_layout use_gpu=%s'
       infer: 'cd PaddleDetection; python tools/infer.py -c configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x1_0_layout.yml --infer_img=docs/images/layout.jpg --output_dir=output_dir/ --draw_threshold=0.5 -o weights=pretrained_model/picodet_lcnet_x1_0_layout.pdparams use_gpu=%s'
       export_model: 'cd PaddleDetection; python tools/export_model.py -c configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x1_0_layout.yml --output_dir=output_inference/ -o weights=pretrained_model/picodet_lcnet_x1_0_layout use_gpu=%s'
       predict: 'cd PaddleDetection; python deploy/python/infer.py --model_dir=output_inference/picodet_lcnet_x1_0_layout/ --image_file=docs/images/layout.jpg --device=%s'
       slim: '--slim_config configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x2_5_layout.yml'
    e2e:
        train: 'cd PaddleOCR; export CUDA_VISIBLE_DEVICES=0; python -m paddle.distributed.launch tools/train.py -c %s -o Global.use_gpu=%s Global.epoch_num=1 Global.save_epoch_step=1 Global.eval_batch_step=200 Global.print_batch_step=10 Global.save_model_dir=output/%s Train.loader.batch_size_per_card=10 Global.print_batch_step=1;'
       get_pretrained_model: 'cd PaddleOCR; wget %s; tar xf %s.tar; rm -rf *.tar; mv %s %s;'
       eval: 'cd PaddleOCR; python tools/eval.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy'
       infer: 'cd PaddleOCR; python tools/infer_e2e.py -c %s  -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.infer_img="./doc/imgs_en/img_10.jpg";'
       export_model: 'cd PaddleOCR; python tools/export_model.py -c %s -o Global.use_gpu=%s Global.pretrained_model=./%s/best_accuracy Global.save_inference_dir=./models_inference/%s;'
       predict: 'cd PaddleOCR; python tools/infer/predict_e2e.py --image_dir=./doc/imgs_en/img623.jpg --e2e_model_dir=./models_inference/%s --e2e_algorithm=PGNet --e2e_pgnet_polygon=True  --use_gpu=%s --use_tensorrt=%s --enable_mkldnn=%s'


det_r50_db++_icdar15:
    model_yaml: configs/det/det_r50_db++_icdar15.yml
    paddle_train_acc: 
    torch_train_acc: 
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/dygraph_v2.1/en_det/det_r50_db_plusplus_icdar15_train.tar
    eval_hmean: 0.865
    det_algorithm:  DB++
    dataset: icdar15

det_r50_db++_td_tr:
    model_yaml: configs/det/det_r50_db++_td_tr.yml 
    paddle_train_acc: 
    torch_train_acc: 
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/dygraph_v2.1/en_det/det_r50_db_plusplus_td_tr_train.tar
    eval_hmean: 0.895
    det_algorithm:  DB++
    dataset: td_tr

ch_PP-OCRv3_det_cml:
    model_yaml: configs/det/ch_PP-OCRv3/ch_PP-OCRv3_det_cml.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_distill_train.tar
    eval_hmean: 0.895
    det_algorithm:  Distillation
    dataset: icdar2015

rec_vitstr_none_ce:
    model_yaml: configs/rec/rec_vitstr_none_ce.yml
    paddle_train_acc: 0.8089 
    torch_train_acc: 79.912
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/rec_vitstr_none_ce_train.tar 
    eval_acc: 0.8093
    rec_image_shape: 1,224,224
    rec_algorithm: ViTSTR
    rec_char_dict_path: ./ppocr/utils/EN_symbol_dict.txt
    dataset: data_lmdb_release

rec_r45_abinet:
    model_yaml: configs/rec/rec_r45_abinet.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/rec_r45_abinet_train.tar
    eval_acc: 0.91580
    rec_image_shape: 3,32,128
    rec_algorithm: ABINet
    rec_char_dict_path: ./ppocr/utils/ic15_dict.txt
    dataset: data_lmdb_release

rec_r45_visionlan:
    model_yaml: configs/rec/rec_r45_visionlan.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/rec_r45_visionlan_train.tar
    eval_acc: 0.90
    rec_image_shape: '3,64,256'
    rec_algorithm: VisionLAN
    rec_char_dict_path: ./ppocr/utils/ic15_dict.txt
    dataset: data_lmdb_release

ch_PP-OCRv3_rec_distillation:
    model_yaml: configs/rec/PP-OCRv3/ch_PP-OCRv3_rec_distillation.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_train.tar
    eval_hmean: 0.895
    det_algorithm:  Distillation
    dataset: SimpleDataSet

sr_tsrn_transformer_strock:
    model_yaml: configs/sr/sr_tsrn_transformer_strock.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/sr_tsrn_transformer_strock_train.tar
    eval_psnr_avg: 20.383493
    eval_ssim_avg: 0.707989 
    sr_image_shape: 3,32,128
    sr_algorithm: Gestalt
    dataset: LMDBDataSetSR

ser_vi_layoutxlm_xfund_zh_udml:
    model_yaml: configs/kie/vi_layoutxlm/ser_vi_layoutxlm_xfund_zh_udml.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/ppstructure/models/vi_layoutxlm/ser_vi_layoutxlm_xfund_pretrained.tar
    eval_hmean: 0.9038
    algorithm: LayoutXML
    dataset: SimpleDataSet

re_vi_layoutxlm_xfund_zh_udml:
    model_yaml: configs/kie/vi_layoutxlm/re_vi_layoutxlm_xfund_zh_udml.yml
    eval_pretrained_model: https://paddleocr.bj.bcebos.com/ppstructure/models/vi_layoutxlm/re_vi_layoutxlm_xfund_pretrained.tar
    eval_hmean: 0.7483
    algorithm: LayoutXML
    dataset: SimpleDataSet

table_master:
   model_yaml: configs/table/table_master.yml
   eval_pretrained_model: https://paddleocr.bj.bcebos.com/ppstructure/models/tablemaster/table_structure_tablemaster_train.tar
   eval_acc: 0.811999998376
   dataset: pubtabnet

SLANet:
   model_yaml: configs/table/SLANet.yml
   eval_pretrained_model: https://paddleocr.bj.bcebos.com/ppstructure/models/slanet/en_ppstructure_mobile_v2.0_SLANet_train.tar
   eval_acc: 0.795999998408
   dataset: pubtabnet

picodet_lcnet_x1_0_layout:
   model_yaml: configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x1_0_layout.yml
   eval_pretrained_model: https://paddleocr.bj.bcebos.com/ppstructure/models/slanet/en_ppstructure_mobile_v2.0_SLANet_train.tar
   eval_acc: 0.795999998408
   dataset: pubtabnet

picodet_lcnet_x2_5_layout:
   model_yaml: configs/picodet/legacy_model/application/layout_analysis/picodet_lcnet_x2_5_layout.yml
   eval_pretrained_model: https://paddleocr.bj.bcebos.com/ppstructure/models/slanet/en_ppstructure_mobile_v2.0_SLANet_train.tar
   eval_acc: 0.795999998408
   dataset: pubtabnet

e2e_r50_vd_pg:
   model_yaml: configs/e2e/e2e_r50_vd_pg.yml
   eval_pretrained_model: https://paddleocr.bj.bcebos.com/dygraph_v2.0/pgnet/en_server_pgnetA.tar
   eval_acc: 0.811999998376
   dataset: PGDataSet
