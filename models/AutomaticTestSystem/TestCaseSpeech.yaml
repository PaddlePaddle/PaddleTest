

csmsc/vits:
     get_pretrained_model: 'cd PaddleSpeech/examples/csmsc/vits; wget https://paddlespeech.bj.bcebos.com/Parakeet/released_models/vits/vits_csmsc_ckpt_1.1.0.zip; unzip vits_csmsc_ckpt_1.1.0.zip; rm -rf *.zip'
     train: 'cd PaddleSpeech/examples/csmsc/vits; source ${PWD}/path.sh; source ${MAIN_ROOT}/utils/parse_options.sh; conf_path=conf/default.yaml; train_output_path=exp/default; sed -i "s/train_max_steps: 350000/train_max_steps: 200/g; s/batch_size: 64/batch_size: 16/g" ${conf_path}; sed -i "s/python3/python/g" ./local/train.sh; rm -rf exp; ./local/train.sh ${conf_path} ${train_output_path}'
     synthesize: 'head -10 ./dump/test/norm/metadata.jsonl > ./metadata_10.jsonl;ckpt_name=snapshot_iter_76.pdz;sed -i "s#dump/test/norm/metadata.jsonl#./metadata_10.jsonl#g;s#python3#python#g" ./local/synthesize.sh; CUDA_VISIBLE_DEVICES=${gpus} ./local/synthesize.sh ${conf_path} ${train_output_path} ${ckpt_name}'
     synthesize_e2e: 'cd PaddleSpeech/examples/csmsc/vits; source path.sh; add_blank=true; FLAGS_allocator_strategy=naive_best_fit; FLAGS_fraction_of_gpu_memory_to_use=0.01; python ${BIN_DIR}/synthesize_e2e.py --config=vits_csmsc_ckpt_1.1.0/default.yaml --ckpt=vits_csmsc_ckpt_1.1.0/snapshot_iter_333000.pdz --phones_dict=vits_csmsc_ckpt_1.1.0/phone_id_map.txt --output_dir=exp/default/test_e2e --text=${BIN_DIR}/../sentences.txt --add-blank=${add_blank}'

zh_en_tts/tts3:
     get_pretrained_model: 'cd PaddleSpeech/examples/csmsc/vits; wget https://paddlespeech.bj.bcebos.com/t2s/chinse_english_mixed/models/fastspeech2_mix_ckpt_0.2.0.zip; unzip fastspeech2_mix_ckpt_0.2.0.zip; wget https://paddlespeech.bj.bcebos.com/Parakeet/released_models/pwgan/pwg_aishell3_ckpt_0.5.zip; unzip pwg_aishell3_ckpt_0.5.zip; rm -rf *.zip'
     train: 'cd PaddleSpeech/examples/zh_en_tts/tts3; source ${PWD}/path.sh; source ${MAIN_ROOT}/utils/parse_options.sh; conf_path=conf/default.yaml; train_output_path=exp/default; sed -i "s/train_max_steps: 350000/train_max_steps: 200/g; s/batch_size: 64/batch_size: 16/g" ${conf_path}; sed -i "s/python3/python/g" ./local/train.sh; rm -rf exp; ./local/train.sh ${conf_path} ${train_output_path}'
     synthesize_e2e: 'cd PaddleSpeech/examples/zh_en_tts/tts3; source path.sh; FLAGS_allocator_strategy=naive_best_fit; FLAGS_fraction_of_gpu_memory_to_use=0.01; python ${BIN_DIR}/../synthesize_e2e.py; --am=fastspeech2_mix --am_config=fastspeech2_mix_ckpt_0.2.0/default.yaml --am_ckpt=fastspeech2_mix_ckpt_0.2.0/snapshot_iter_99200.pdz --am_stat=fastspeech2_mix_ckpt_0.2.0/speech_stats.npy --voc=pwgan_aishell3 --voc_config=pwg_aishell3_ckpt_0.5/default.yaml --voc_ckpt=pwg_aishell3_ckpt_0.5/snapshot_iter_1000000.pdz --voc_stat=pwg_aishell3_ckpt_0.5/feats_stats.npy --lang=mix --text=${BIN_DIR}/../sentences_mix.txt --output_dir=exp/default/test_e2e --phones_dict=fastspeech2_mix_ckpt_0.2.0/phone_id_map.txt --speaker_dict=fastspeech2_mix_ckpt_0.2.0/speaker_id_map.txt --spk_id=174 --inference_dir=exp/default/inference'
