# 目标是减少写case的冗余
# 或者都不设置，就会默认支持全量(linux的全量是: 单卡、双卡，cpu，windows：单卡+cpu， mac：cpu)
# 框架应该在pytest的基础上做一层封装调度；支持指定模型列表，全量列表，部分阶段
# 基准值框架给托管起来（分支+硬件信息+系统/ 分支+系统）存储

# TODO 在最前面build的操作中执行要跑的模型bs除以3
# TODO pretrained_model qa_yaml_name 自动替换
# TODO pretrained_model 要根据使用训好的模型和预训练的模型进行替换，默认显示用训好的模型，预训练模型TODO
# TODO Global_epochs根据不同模型在在生成时自动替换
# TODO 只写特殊的yaml，其它的进行自动生成，主要难点在于 pretrained_model 的路径以及一些全局变量的传递
# TODO multi_convergence 和 amp时 要unset掉环境变量

case:
  linux:
    base: ./base/ImageNet_base.yaml
    train:
      -
        name: multi
        cmd : -m paddle.distributed.launch tools/train.py
        params:
          - -o Global.epochs=5
          - -o Global.save_interval=5
          - -o Global.eval_interval=5
          - -o Global.seed=1234
          - -o DataLoader.Train.loader.num_workers=0
          - -o DataLoader.Train.sampler.shuffle=False
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 10
            threshold: 0.01
            evaluation: "-"
      -
        name: single
        cmd : tools/train.py
        params:
          - -o Global.epochs=2
          - -o Global.save_interval=2
          - -o Global.eval_interval=2
          - -o Global.seed=1234
          - -o DataLoader.Train.loader.num_workers=0
          - -o DataLoader.Train.sampler.shuffle=False
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: multi_static
        cmd : -m paddle.distributed.launch ppcls/static/train.py
        params:
          - -o Global.epochs=5
          - -o Global.save_interval=5
          - -o Global.eval_interval=5
          - -o Global.seed=1234
          - -o DataLoader.Train.loader.num_workers=0
          - -o DataLoader.Train.sampler.shuffle=False
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: single_static
        cmd : ppcls/static/train.py
        params:
          - -o Global.epochs=2
          - -o Global.save_interval=2
          - -o Global.eval_interval=2
          - -o Global.seed=1234
          - -o DataLoader.Train.loader.num_workers=0
          - -o DataLoader.Train.sampler.shuffle=False
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: multi_convergence
        cmd : -m paddle.distributed.launch tools/train.py
        params:
          - -o Global.epochs=delete
          - -o Global.save_interval=delete
          - -o Global.eval_interval=delete
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: single_convergence
        cmd : tools/train.py
        params:
          - -o Global.epochs=delete
          - -o Global.save_interval=delete
          - -o Global.eval_interval=delete
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
    eval:
      -
        name: trained
        cmd: -m paddle.distributed.launch tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_trained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: pretrained
        cmd: -m paddle.distributed.launch tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: single_trained
        cmd:  tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_trained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
      -
        name: single_pretrained
        cmd:  tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
    infer:
      -
        name: trained
        cmd: tools/infer.py
        params:
          - -o Global.pretrained_model=${eval_trained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          class_ids:
            base: [22, 22, 22, 22, 22]
            threshold: 0
            evaluation: "="
      -
        name: pretrained
        cmd: tools/infer.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          class_ids:
            base: [8, 7, 86, 82, 476]
            threshold: 0
            evaluation: "="
    export:
      -
        name: trained
        cmd: tools/export_model.py
        params:
          - -o Global.pretrained_model=${eval_trained_model}
          - -o Global.save_inference_dir=${export_trained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
      -
        name: pretrained
        cmd: tools/export_model.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.save_inference_dir=${export_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
    predict:
      -
        name: trained
        cmd: python/predict_cls.py
        params:
          - -c configs/inference_cls.yaml
          - -o Global.infer_imgs="./images"
          - -o Global.inference_model_dir=${predict_trained_model}
          - -o Global.use_gpu=${set_cuda_flag}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          class_ids:
            base: [11, 11, 11, 11]
            threshold: 0
            evaluation: "="
      -
        name: pretrained
        cmd: python/predict_cls.py
        params:
          - -c configs/inference_cls.yaml
          - -o Global.infer_imgs="./images"
          - -o Global.inference_model_dir=${predict_pretrained_model}
          - -o Global.use_gpu=${set_cuda_flag}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          class_ids:
            base: [443, 84, 808, 511]
            threshold: 0
            evaluation: "="

  # linux_cpu:  #暂时只写了cpu，一般不会有人用cpu_eval
    # base: ./base/ImageNet_base.yaml
  #   train:
  #     -
  #       name: cpu
  #       params:
  #         - -o Global.device=cpu
  #       result:
  #         exit_code: 0

  windows:
    base: ./base/ImageNet_base.yaml
    eval:
      -
        name: pretrained
        cmd:  tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
    infer:
      -
        name: pretrained
        cmd: tools/infer.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          class_ids:
            base: [8, 7, 86, 82, 476]
            threshold: 0
            evaluation: "="
    export:
      -
        name: pretrained
        cmd: tools/export_model.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.save_inference_dir=${export_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
    predict:
      -
        name: pretrained
        cmd: python/predict_cls.py
        params:
          - -c configs/inference_cls.yaml
          - -o Global.infer_imgs="./images"
          - -o Global.inference_model_dir=${predict_pretrained_model}
          - -o Global.use_gpu=${set_cuda_flag}
          - -o Global.output_dir=output/${qa_yaml_name}
        result:
          class_ids:
            base: [443, 84, 808, 511]
            threshold: 0
            evaluation: "="

  windows_cpu:
    base: ./base/ImageNet_base.yaml
    train:
      -
        name: single
        params:
          - -o Global.device=${set_cuda_flag}
    eval:
      -
        name: trained
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd:  tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
    infer:
      -
        name: infer
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd: tools/infer.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
        result:
          class_ids:
            base: [8, 7, 86, 82, 476]
            threshold: 0
            evaluation: "="
    export:
      -
        name: trained
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd: tools/export_model.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.save_inference_dir=${export_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
    predict:
      -
        name: trained
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd: python/predict_cls.py
        params:
          - -c configs/inference_cls.yaml
          - -o Global.infer_imgs="./images"
          - -o Global.inference_model_dir=${predict_pretrained_model}
          - -o Global.use_gpu=${set_cuda_flag}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
        result:
          class_ids:
            base: [443, 84, 808, 511]
            threshold: 0
            evaluation: "="

  mac:
    base: ./base/ImageNet_base.yaml
    train:
      -
        name: single
        params:
          - -o Global.device=${set_cuda_flag}
    eval:
      -
        name: trained
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd:  tools/eval.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
        result:
          ${kpi_value_eval}:
            base: 20
            threshold: 0.01
            evaluation: "-"
    infer:
      -
        name: infer
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd: tools/infer.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
        result:
          class_ids:
            base: [8, 7, 86, 82, 476]
            threshold: 0
            evaluation: "="
    export:
      -
        name: trained
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd: tools/export_model.py
        params:
          - -o Global.pretrained_model=${eval_pretrained_model}
          - -o Global.save_inference_dir=${export_pretrained_model}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
    predict:
      -
        name: trained
        params:
          - -o Global.device=${set_cuda_flag}
      -
        name: pretrained
        cmd: python/predict_cls.py
        params:
          - -c configs/inference_cls.yaml
          - -o Global.infer_imgs="./images"
          - -o Global.inference_model_dir=${predict_pretrained_model}
          - -o Global.use_gpu=${set_cuda_flag}
          - -o Global.output_dir=output/${qa_yaml_name}
          - -o Global.device=${set_cuda_flag}
        result:
          class_ids:
            base: [443, 84, 808, 511]
            threshold: 0
            evaluation: "="

function: paddlelas_imagenet_parse
