# 目标是减少写case的冗余
# 或者都不设置，就会默认支持全量(linux的全量是: 单卡、双卡，cpu，windows：单卡+cpu， mac：cpu)
# 框架应该在pytest的基础上做一层封装调度；支持指定模型列表，全量列表，部分阶段
# 基准值框架给托管起来（分支+硬件信息+系统/ 分支+系统）存储

# TODO: 需要增加固定随机量的全局变量
# TODO: 显存的设置用全局变量控制
# TODO: rd_yaml_path  qa_yaml_name 需要约定
# bs=1 避免OOM
# TODO：params_dir看是否要加，要加的话能串联起train eval和后面阶段，否则eval是使用的就是初始化参数，无法判断最新训出的模型是什么情况
case:
  linux:
    base: ./base/ImageNet_base.yaml
    train:
      name: base_train
      cmd : -m paddle.distributed.launch tools/train.py
      params:
        - -c ${rd_yaml_path}
        - -o Global.epochs=1
        - Global.save_interval=1
        - Global.eval_interval=1
      result:
        exit_code:
          base: 0
          threshold: 0
          evaluation: "="
    eval:
      name: base_eval
      cmd: -m paddle.distributed.launch tools/eval.py
      params:
        - -c ${rd_yaml_path}
      result:
        exit_code:
          base: 0
          threshold: 0
          evaluation: "="
    infer:
      name: base_infer
      cmd: tools/infer.py
      params:
        - -c ${rd_yaml_path}
      result:
        exit_code:
          base: 0
          threshold: 0
          evaluation: "="
    export:
      name: base_export
      cmd: tools/export_model.py
      params:
        - -c ${rd_yaml_path}
        - -o Global.save_inference_dir=./inference/${qa_yaml_name}
      result:
        exit_code:
          base: 0
          threshold: 0
          evaluation: "="
    predict:
      name: base_predict
      cmd: python/predict_cls.py
      params:
        - -c configs/inference_cls.yaml
        - -o Global.inference_model_dir=../inference/${qa_yaml_name}
      result:
        exit_code:
          base: 0
          threshold: 0
          evaluation: "="
  windows:
    base: ./base/ImageNet_base.yaml
  mac:
    base: ./base/ImageNet_base.yaml
    train:
      -
        name : mac_train
        params:
          - Global.device=cpu #覆盖
