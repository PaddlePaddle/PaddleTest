case:
  linux:
    train:
      -
        name: multi
        path: examples/question_generation/unimo-text
        cmd: python -m paddle.distributed.launch --log_dir ./unimo/finetune/log train.py
        params:
          - --dataset_name=dureader_qg
          - --model_name_or_path="unimo-text-1.0"
          - --save_dir=./unimo/finetune/checkpoints
          - --output_path ./unimo/finetune/predict.txt
          - --logging_steps=1
          - --save_steps=500
          - --epochs=1
          - --batch_size=16
          - --learning_rate=1e-5
          - --warmup_proportion=0.02
          - --weight_decay=0.01
          - --max_seq_len=512
          - --max_target_len=30
          - --do_train
          - --do_predict
          - --max_dec_len=20
          - --min_dec_len=3
          - --num_return_sequences=1
          - --template=1
          - --device=gpu
    eval:
      -
        name: eval
        path: examples/question_generation/unimo-text
        cmd:  python predict.py
        params:
          - --model_name_or_path=./unimo/finetune/checkpoints/model_best
          - --output_path=./predict.txt
          - --logging_steps=100
          - --batch_size=16
          - --max_seq_len=512
          - --max_target_len=30
          - --do_predict
          - --max_dec_len=20
          - --min_dec_len=3
          - --template=1
          - --device=gpu
    infer: skipped
    export:
      -
        name: eval
        path: examples/question_generation/unimo-text
        cmd: python export_model.py
        params:
          - --model_name_or_path ./unimo/finetune/checkpoints/model_best
          - --inference_model_dir ./export_checkpoint
          - --max_dec_len 50
          - --use_fp16_decoding
    predict: skipped
  windows:
    train:
      -
        name: single
        path: examples/question_generation/unimo-text
        cmd: python -m paddle.distributed.launch --log_dir ./unimo/finetune/log train.py
        params:
          - --dataset_name=dureader_qg
          - --model_name_or_path="unimo-text-1.0"
          - --save_dir=./unimo/finetune/checkpoints
          - --output_path ./unimo/finetune/predict.txt
          - --logging_steps=1
          - --save_steps=500
          - --epochs=1
          - --batch_size=16
          - --learning_rate=1e-5
          - --warmup_proportion=0.02
          - --weight_decay=0.01
          - --max_seq_len=512
          - --max_target_len=30
          - --do_train
          - --do_predict
          - --max_dec_len=20
          - --min_dec_len=3
          - --num_return_sequences=1
          - --template=1
          - --device=gpu
    eval:
      -
        name: eval
        path: examples/question_generation/unimo-text
        cmd:  python predict.py
        params:
          - --model_name_or_path=./unimo/finetune/checkpoints/model_best
          - --output_path=./predict.txt
          - --logging_steps=100
          - --batch_size=16
          - --max_seq_len=512
          - --max_target_len=30
          - --do_predict
          - --max_dec_len=20
          - --min_dec_len=3
          - --template=1
          - --device=gpu
    infer: skipped
    export:
      -
        name: eval
        path: examples/question_generation/unimo-text
        cmd: python export_model.py
        params:
          - --model_name_or_path ./unimo/finetune/checkpoints/model_best
          - --inference_model_dir ./export_checkpoint
          - --max_dec_len 50
          - --use_fp16_decoding
    predict: skipped
  windows_cpu:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped

  mac:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped
