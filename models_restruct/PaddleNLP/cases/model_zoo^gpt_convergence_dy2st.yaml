case:
  linux_convergence:
    train:
      -
        name: prepare_datasets
        path: model_zoo/gpt-3/tasks/gpt
        cmd: mkdir data && cd data && wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k_ids.npy && wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k_idx.npz
      
      - 
        name: dy2st_baseline
        path: model_zoo/gpt-3/tasks/gpt
        cmd: python train_pir.py
        params: 
          - -c ../../ppfleetx/configs/nlp/gpt/pretrain_gpt_345M_single_card.yaml 
          - -o Global.micro_batch_size=1 
          - -o Global.local_batch_size=1 
          - -o Global.to_static=False 
          - -o Engine.max_steps=5000

      -
        name: dy2st_pri_to_static
        path: model_zoo/gpt-3/tasks/gpt
        cmd: python train_pir.py
        params: 
          - -c ../../ppfleetx/configs/nlp/gpt/pretrain_gpt_345M_single_card.yaml 
          - -o Global.micro_batch_size=1 
          - -o Global.local_batch_size=1 
          - -o Global.to_static=False 
          - -o Engine.max_steps=5000
      -
        name: dy2st_pri_to_static_prim
        path: model_zoo/gpt-3/tasks/gpt
        cmd: python train_pir.py
        params: 
          - -c ../../ppfleetx/configs/nlp/gpt/pretrain_gpt_345M_single_card.yaml 
          - -o Global.micro_batch_size=1 
          - -o Global.local_batch_size=1 
          - -o Global.to_static=False 
          - -o Engine.max_steps=5000
