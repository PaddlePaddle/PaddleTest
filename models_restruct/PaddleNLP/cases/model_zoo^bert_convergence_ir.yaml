case:
  linux_convergence:
    train:
      -
        name: prepare_datasets_seqlen128
        path: model_zoo/bert/
        cmd: wget https://paddle-qa.bj.bcebos.com/paddlenlp/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5.tar.gz && tar -xzvf hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5.tar.gz
      -
        name: baseline
        path: model_zoo/bert
        cmd: python run_pretrain.py
        params:
          - --max_predictions_per_seq 20
          - --learning_rate 1e-4
          - --weight_decay 1e-2
          - --adam_epsilon 1e-6
          - --warmup_steps 10000
          - --output_dir ./ir_baseline/
          - --logging_steps 1
          - --save_steps 10000
          - --model_type bert
          - --fuse_transformer false
          - --input_dir ./hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/training/
          - --model_name_or_path bert-base-uncased
          - --max_step 10000
          - --batch_size 128
          - --seed 42
          - --to_static True
          - --use_amp True
          - --amp_level O2
          - --cinn True
      -
        name: ir
        path: model_zoo/bert
        cmd: python run_pretrain.py
        params:
          - --max_predictions_per_seq 20
          - --learning_rate 1e-4
          - --weight_decay 1e-2
          - --adam_epsilon 1e-6
          - --warmup_steps 10000
          - --output_dir ./ir/
          - --logging_steps 1
          - --save_steps 10000
          - --model_type bert
          - --fuse_transformer false
          - --input_dir ./hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/training/
          - --model_name_or_path bert-base-uncased
          - --max_step 10000
          - --batch_size 128
          - --seed 42
          - --to_static True
          - --use_amp True
          - --amp_level O2
