case:
  linux:
    train:
      -
        name: prepare
        path: model_zoo/bert
        cmd: wget -q https://paddle-qa.bj.bcebos.com/paddlenlp/bert.tar.gz && tar -xzvf bert.tar.gz
      -
        name: pretrain
        path: model_zoo/bert
        cmd: python -m paddle.distributed.launch  run_pretrain.py
        params:
          - --model_type bert
          - --model_name_or_path bert-base-uncased
          - --batch_size 4
          - --input_dir bert/
          - --output_dir pretrained_models/
          - --logging_steps 1
          - --save_steps 2
          - --max_steps 2
          - --device gpu
          - --use_amp True
          - --to_static True
        result:
          loss:
            base: 6.28685
            threshold: 0.01
            evaluation: "="
      -
        name: fintune_glue
        path: model_zoo/bert
        cmd: python -m paddle.distributed.launch run_glue_trainer.py
        params:
          - --model_name_or_path bert-base-uncased
          - --task_name SST2
          - --max_seq_length 128
          - --per_device_train_batch_size 32
          - --per_device_eval_batch_size 32
          - --learning_rate 2e-5
          - --num_train_epochs 3
          - --logging_steps 1
          - --save_steps 1
          - --max_steps 1
          - --output_dir ./tmp/
          - --device gpu
          - --fp16 False
          - --do_train
          - --do_eval
        result:
          loss:
            base: 1.456469
            threshold: 0.01
            evaluation: "="
    eval: skipped
    infer: skipped
    export:
      -
        name: export
        path: model_zoo/bert
        cmd:  python -u ./export_model.py
        params:
          - --model_type bert
          - --model_path bert-base-uncased
          - --output_path ./infer_model/model
    predict: skipped

  windows:
    train:
      -
        name: prepare
        path: model_zoo/bert
        cmd: wget -q https://paddle-qa.bj.bcebos.com/paddlenlp/bert.tar.gz && tar -xzvf bert.tar.gz
      -
        name: pretrain
        path: model_zoo/bert
        cmd: python -m paddle.distributed.launch  run_pretrain.py
        params:
          - --model_type bert
          - --model_name_or_path bert-base-uncased
          - --batch_size 16
          - --input_dir bert/
          - --output_dir pretrained_models/
          - --logging_steps 1
          - --save_steps 2
          - --max_steps 2
          - --device gpu
          - --use_amp True
        result:
          loss:
            base: 6.28685
            threshold: 0.01
            evaluation: "="
      -
        name: fintune_glue
        path: model_zoo/bert
        cmd: python -m paddle.distributed.launch run_glue.py
        params:
          - --model_type bert
          - --model_name_or_path bert-base-uncased
          - --task_name SST2
          - --logging_steps 1
          - --save_steps 2
          - --max_steps 2
          - --output_dir ./tmp/
          - --device gpu
          - --use_amp True
        result:
          loss:
            base: 1.456469
            threshold: 0.01
            evaluation: "="
    eval: skipped
    infer: skipped
    export:
      -
        name: export
        path: model_zoo/bert
        cmd:  python -u ./export_model.py
        params:
          - --model_type bert
          - --model_path bert-base-uncased
          - --output_path ./infer_model/model
    predict:
      -
        name: predict
        path: model_zoo/bert
        cmd: python -u ./predict_glue.py
        params:
          - --task_name SST2
          - --model_type bert
          - --model_path ./infer_model/model
          - --batch_size 32
          - --max_seq_length 128
      -
        name: predict_sample_data_SST2
        path: model_zoo/bert
        cmd: python -u ./predict_glue.py
        params:
          - --task_name SST2
          - --model_type bert
          - --model_path ./infer_model/model
          - --device gpu
          - --max_seq_length 128

  windows_cpu:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped

  mac:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped
