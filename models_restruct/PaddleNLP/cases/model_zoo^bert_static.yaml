case:
  linux:
    train:
      -
        name: prepare
        path: model_zoo/bert/static
        cmd: wget -q https://paddle-qa.bj.bcebos.com/paddlenlp/bert_static.tar.gz && tar -xzvf bert_static.tar.gz 
      -
        name: pretrain
        path: model_zoo/bert/static
        cmd: python -m paddle.distributed.launch --gpus "0,1" run_pretrain.py
        params:
          - --model_type bert
          - --model_name_or_path bert-base-uncased
          - --max_predictions_per_seq 20
          - --batch_size 32
          - --learning_rate 1e-4
          - --weight_decay 1e-2
          - --adam_epsilon 1e-6
          - --warmup_steps 10000
          - --input_dir ./bert_static/
          - --output_dir pretrained_models/
          - --logging_steps 1
          - --save_steps 2
          - --max_steps 2
          - --device gpu
          - --use_amp True 
        result:
          loss:
            base: 6.28685
            threshold: 0.01
            evaluation: "="
      -
        name: fintune
        path: model_zoo/bert/static
        cmd: python -m paddle.distributed.launch --gpus "0" run_glue.py
        params:
          - --model_type bert
          - --model_name_or_path bert-base-uncased 
          - --task_name SST-2 
          - --max_seq_length 128 
          - --batch_size 32  
          - --learning_rate 2e-5
          - --num_train_epochs 3
          - --logging_steps 1
          - --save_steps 2
          - --max_steps 2
          - --output_dir ./tmp/
          - --device gpu
        result:
          loss:
            base: 1.456469
            threshold: 0.01
            evaluation: "="
    eval: skipped
    infer: skipped
    export: skipped
    predict: 
      -
        name: predict
        path: model_zoo/bert/static
        cmd: python -u ./predict_glue.py
        params:
          - --task_name SST-2
          - --model_type bert
          - --model_path ./tmp/model_2/infer_model
          - --batch_size 32 
          - --max_seq_length 128
