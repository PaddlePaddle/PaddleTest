case:
  linux:
    train:
      -
        name: prepare
        path: legacy/model_zoo/gpt
        cmd: mkdir data && cd data && wget https://paddlenlp.bj.bcebos.com/models/transformers/gpt/data/gpt_en_dataset_300m_ids.npy && wget https://paddlenlp.bj.bcebos.com/models/transformers/gpt/data/gpt_en_dataset_300m_idx.npz
      -
        name: pretrain
        path: legacy/model_zoo/gpt
        cmd: python -m paddle.distributed.launch  run_pretrain_static.py
        params:
          - --model_name_or_path __internal_testing__/gpt
          - --model_type gpt
          - --input_dir "./data"
          - --output_dir "output"
          - --weight_decay 0.01
          - --grad_clip 1.0
          - --max_steps 2
          - --save_steps 2
          - --dp_degree 8
          - --decay_steps 320000
          - --warmup_rate 0.01
          - --micro_batch_size 2
          - --device gpu
        result:
          loss:
            base: 1.456469
            threshold: 0.01
            evaluation: "="
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped

  windows:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped

  windows_cpu:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped

  mac:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped
