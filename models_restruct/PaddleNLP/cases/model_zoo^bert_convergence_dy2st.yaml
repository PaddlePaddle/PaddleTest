case:
  linux_convergence:
    train:
      -
        name: prepare_datasets_seqlen128
        path: model_zoo/bert/data
        cmd: wget -q https://bj.bcebos.com/paddlenlp/datasets/benchmark_wikicorpus_en_seqlen128.tar && tar -xf benchmark_wikicorpus_en_seqlen128.tar
      -
        name: dy2st_prim_cinn
        path: model_zoo/bert
        cmd: python run_pretrain.py
        params:
          - --max_predictions_per_seq 20
          - --learning_rate 1e-4
          - --weight_decay 1e-2
          - --adam_epsilon 1e-6
          - --warmup_steps 10000
          - --output_dir ./primcinn/
          - --logging_steps 1
          - --save_steps 10
          - --model_type bert
          - --fuse_transformer false
          - --input_dir ./data/wikicorpus_en_seqlen128
          - --model_name_or_path bert-base-uncased
          - --max_step 10
          - --batch_size 128
          - --seed 42
          - --to_static True
          - --use_amp True
          - --amp_level O2
      -
        name: dy2st_baseline
        path: model_zoo/bert
        cmd: python run_pretrain.py
        params:
          - --max_predictions_per_seq 20
          - --learning_rate 1e-4
          - --weight_decay 1e-2
          - --adam_epsilon 1e-6
          - --warmup_steps 10000
          - --output_dir ./dy2st/
          - --logging_steps 1
          - --save_steps 10
          - --model_type bert
          - --fuse_transformer false
          - --input_dir ./data/wikicorpus_en_seqlen128
          - --model_name_or_path bert-base-uncased
          - --max_step 10
          - --batch_size 128
          - --seed 42
          - --to_static True
          - --use_amp True
          - --amp_level O2
      
