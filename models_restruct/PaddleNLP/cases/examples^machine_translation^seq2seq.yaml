case:
  linux:
    train:
      -
        name: pretrain
        path: examples/machine_translation/seq2seq/
        cmd: python train.py
        params:
          - --num_layers 2 
          - --hidden_size 512 
          - --batch_size 128 
          - --max_epoch 1 
          - --log_freq 1 
          - --dropout 0.2 
          - --init_scale  0.1 
          - --max_grad_norm 5.0 
          - --device gpu 
          - --model_path ./attention_models 
    eval: 
      -
        name: eval
        path: examples/machine_translation/seq2seq/
        cmd: python predict.py
        params:
          - --num_layers 2 
          - --hidden_size 512 
          - --batch_size 128 
          - --dropout 0.2 
          - --init_scale  0.1 
          - --max_grad_norm 5.0 
          - --init_from_ckpt attention_models/0 
          - --infer_output_file infer_output.txt 
          - --beam_size 10 
          - --device gpu 
    infer: skipped
    export:
      -
        name: export
        path: examples/machine_translation/seq2seq/
        cmd:  python export_model.py
        params:
          - --num_layers 2 
          - --hidden_size 512 
          - --batch_size 128 
          - --dropout 0.2 
          - --init_scale  0.1 
          - --max_grad_norm 5.0 
          - --init_from_ckpt attention_models/0.pdparams 
          - --beam_size 10 
          - --export_path ./infer_model/model 
    predict: 
      -
        name: predict
        path: examples/machine_translation/seq2seq/deploy/python
        cmd:  python infer.py
        params:
          - --export_path ../../infer_model/model 
          - --device gpu 
          - --batch_size 128 
          - --infer_output_file infer_output.txt

  windows:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped
  windows_cpu:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped

  mac:
    train: skipped
    eval: skipped
    infer: skipped
    export: skipped
    predict: skipped
